---
title: "MovieLens Project"
author: "Abhishek Talari"
date: "2023-12-05"
output:
  word_document: default
  pdf_document: default
---
## Executive summary
The movielens dataset has over 10 million ratings for more than 10,000 movies given by over 72,000 users. The data set includes the identification of the user, movie, rating, genre, and timestamp. 

The goal of this project is to predict movie ratings. To do that, we partitioned data into training set and testing set. We then fit our model with testing set and will calculate the RMSE values. As the dataset is very sparse, we also included regularization in the model.

```{r Creat test and validation sets, echo=FALSE, message=FALSE, warning=FALSE}
##########################################################
# Create edx and final_holdout_test sets 
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)
dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)
movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)
ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))
movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))
movielens <- left_join(ratings, movies, by = "movieId")
# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
# set.seed(1) # if using R 3.5 or earlier
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]
# Make sure userId and movieId in final hold-out test set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")
# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

```{r Loading packages, message=FALSE, warning=FALSE, echo=FALSE, results="hide"}
requiredPackages <- c("tidyverse", "rafalib", "ggpubr", "knitr", "raster")
lapply(requiredPackages, library, character.only = TRUE)
```

##Analysis 

Observation 1: From the data set, we see that there are `r length(unique(edx$userId))` unique users who have provided ratings and `r length(unique(edx$movieId))` unique movies were rated. If we have to think about all the possible combinations, there would be more than 746 million combinations for users and movies. But our test set has around 9 million rows that implies that not every user has rated every movie.
This number of ratings is only `r paste0(round(dim(edx)[1] / (length(unique(edx$userId)) * length(unique(edx$movieId))) * 100, 2), "%")` of all possible combinations, which necessitates a sparse matrix.

Observation 2: In addition to not having every movie rated by every user, we also see that i) few movies have been rated more than the others and ii) few users have rated more than the others. These can be seen in the two histograms below.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Some movies are more rated than others
hist_movies <- edx %>%
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 40, fill = "blue") + 
  labs(title = "Ratings per movie",
       x = "Number of ratings per movie", y = "Count", fill = element_blank()) +
  theme_classic()

hist_users <- edx %>%
  count(userId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 40, fill = "blue") + 
  labs(title = "Ratings per user",
       x = "Number of ratings per user", y = "Count", fill = element_blank()) +
  theme_classic()

ggarrange(hist_movies, hist_users,
          ncol = 2, nrow = 1)
```

Observation 3: From the below histogram of ratings, users rated more frequently in integers than half-integer and the ratings distribution is left-skewed.

```{r message=FALSE, warning=FALSE, echo=FALSE}
edx %>%
  ggplot(aes(rating)) +
    geom_histogram(fill = "steelblue") + 
    labs(title = "Histogram of ratings",
       x = "Ratings", y = "Count", fill = element_blank()) +
  theme_classic()
```

Observation 4: There are 20 different classifications of movie genres.
They are as given below:
```{r message=FALSE, warning=FALSE, echo=FALSE}
unique_genres_list <- str_extract_all(unique(edx$genres), "[^|]+") %>%
  unlist() %>%
  unique()

unique_genres_list
```

Observation 5: It is important to notice that few genres have lot more ratings than others. 
Drama and Comedy are the most rated genre types. 
Drama and Film-noir are the better-rated genre types.
Horror is the worst rated genre type.
```{r message=FALSE, warning=FALSE, echo=FALSE}
# Creating the long version of both the train and validation datasets. With separeted genres
edx_genres <- edx %>%
  separate_rows(genres, sep = "\\|", convert = TRUE)
validation_genres <- validation %>%
  separate_rows(genres, sep = "\\|", convert = TRUE)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
hist_genres <- ggplot(edx_genres, aes(x = reorder(genres, genres, function(x) - length(x)))) +
  geom_bar(fill = "steelblue") +
  labs(title = "Ratings per genre",
       x = "Genre", y = "Counts") +
   scale_y_continuous(labels = paste0(1:4, "M"),
                      breaks = 10^6 * 1:4) +
  coord_flip() +
  theme_classic()

boxplot_genre_ratings <- ggplot(edx_genres, aes(genres, rating)) + 
  geom_boxplot(fill = "steelblue", varwidth = TRUE) + 
  labs(title = "Movie ratings per genre",
       x = "Genre", y = "Rating", fill = element_blank()) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

hist_genres
boxplot_genre_ratings
```

We will be using Root Mean Square Error (RMSE) to measure how close the predictions are to the true values in the validation set.
```{r}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

Developing the model:

Here, we first start with the most simple model to have a baseline: predict the same rating regardless of the user, movie or genre.

The model would look like this:
$Y_{u,i} = \mu + \epsilon_{u,i}$

Where $u$ is the index for users, $i$ for movies.
The estimate for $\mu$ is the average of all ratings, which is `r mean(edx$rating)`.

```{r Method: just the average, message=FALSE, warning=FALSE, echo=FALSE}
mu_hat <- mean(edx$rating)
mod_average <- RMSE(edx$rating, mu_hat)

rmse_results <- tibble(Method = "Just the average", RMSE = mod_average)
kable(rmse_results)
```

Modelling movie effects:

Factoring the movie effects into the equation to improve the model. We estimate the movie effect as the average of the ratings by a movie.

```{r Modeling movie effects, message=FALSE, warning=FALSE, echo=FALSE}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu_hat))

predicted_ratings <- mu_hat + validation %>% 
  left_join(movie_avgs, by = 'movieId') %>%
  pull(b_i)

predicted_ratings <- clamp(predicted_ratings, 0.5, 5)

mod_m <- RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Movie Effect Model",
                                 RMSE = mod_m))
```
```{r message=FALSE, warning=FALSE, echo=FALSE}
kable(rmse_results[2,])
```

Modelling user effects:

Factoring both movie and user effects to improve the model.We estimate the user effect as the average of the ratings per user.

```{r Adding Users effects, message=FALSE, warning=FALSE, echo=FALSE}
user_avgs <- edx %>% 
  left_join(movie_avgs, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu_hat - b_i))

predicted_ratings <- validation %>% 
  left_join(movie_avgs, by = 'movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  mutate(pred = mu_hat + b_i + b_u) %>%
  pull(pred)

predicted_ratings <- clamp(predicted_ratings, 0.5, 5)

mod_m_u <- RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Movie + User Effects Model",  
                                 RMSE = mod_m_u))
```
```{r message=FALSE, warning=FALSE, echo=FALSE}
kable(rmse_results[3,])
```

Regularization:

Regularization allows us to penalize estimates constructed using sample sizes.  The larger the penalty parameter $\lambda$, the more the estimate is shrunk. As $\lambda$ is a tuning parameter, we are doing a grid search to choose its optimal value. 

```{r Final model with regularization, message=FALSE, warning=FALSE, echo=FALSE}
lambdas <- seq(11.5, 12.5, 0.2)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(edx$rating)
  
  b_i <- edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  b_g <- edx_genres %>%
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by="userId") %>%
    group_by(genres) %>%
    summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+l))
    
  predicted_ratings <- validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  predicted_ratings <- clamp(predicted_ratings, 0.5, 5)
  
  return(RMSE(predicted_ratings, validation$rating))
})

plot_rmses <- qplot(lambdas, rmses)
lambda <- lambdas[which.min(rmses)]

rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Regularized Movie + User Effect Model",RMSE = min(rmses)))
kable(rmse_results[4,])
```

##Results

To predict movie ratings, we built models that considered movie and user effects. The best model considered all, achieving an RMSE of `r rmse_results[4,]`. The movie effect decreased RMSE the most, suggesting that the movie in itself is of greatest importance to explain the rating.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
kable(rmse_results)
```

##Conclusion

The project's goal was to predict movie ratings with over 10 million evaluations. To do that, we considered the impact of movies and users. To avoid over-fitting we divided the data set into train and validation. We have computed the RMSE for the models, along with regularization. The best fitted model achieved an RMSE of `r rmse_results[4,]`, which is considered very good as for the course's standards. Hence, we are not proceeding to fine-tune the model further.

Tme model that we developed did not consider genre impact. As for the future work, the model can be extrapolated to consider the impact of genres to the ratings. It would have been interesting to have more information about the users (e.g. age and gender) and the movies (e.g. actors, director and language) to try to improve the model.